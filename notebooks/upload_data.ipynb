{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ea34bc",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3985626",
   "metadata": {},
   "source": [
    "**Libraries & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222b67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f31fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safaty check: pandas version\n",
    "# pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff6314",
   "metadata": {},
   "source": [
    "## Prepare dataset for ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1467406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset from parquet file\n",
    "df = pd.read_parquet('../yellow_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275bad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369769, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4674ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "RatecodeID                      float64\n",
       "store_and_fwd_flag               object\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "airport_fee                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check df dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301e537",
   "metadata": {},
   "source": [
    "**Because we are using _parquet_ format, and the variables were parsed to its correct data types, the `dtypes` attribute already show the correct parsing.**\n",
    "\n",
    "Anyway, we will transform this data from **_.parquet_** to **_.csv_**. That will alllow us to use `pandas.read_csv` combined with the argument `iterator = True` later. It will be usefull since we will be loading the data to our database in batches/chuncks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf9ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From parquet to CSV\n",
    "# df.to_csv('./yellow_tripdata_2021-01.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44441048",
   "metadata": {},
   "source": [
    "The IO module in pandas allows us to get the correct SQL syntax for creating a table exactly as we need it.\n",
    "\n",
    "Let's make use of this convenient tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eec8273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"yello_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"tpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"passenger_count\" REAL,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" REAL,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL,\n",
      "  \"airport_fee\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get SQL command to create tabel from pandas DataFrame\n",
    "print(pd.io.sql.get_schema(df, name = 'yello_taxi_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32e24a",
   "metadata": {},
   "source": [
    "**We can also get more specific SQL code according to the database tool we are using.** In this case, we are using **PosgtreSQL**.\n",
    "\n",
    "For that, we need first to create a connection to the database and use that connection on the `pandas.io` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854519dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create postgres connection\n",
    "# Docker engine & postgres container running\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/nyc_taxi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472136df",
   "metadata": {},
   "source": [
    "Finally, let's see the SQL syntax specific for **PostgreSQL**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8802ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yello_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count FLOAT(53), \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\tairport_fee FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create SQL code for initiating schemma\n",
    "print(pd.io.sql.get_schema(df, name = 'yello_taxi_data', con = engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b73ee",
   "metadata": {},
   "source": [
    "We can now create a SQL statement script to create the tables within our databse.\n",
    "\n",
    "But there is even a simpler way to do the same task. Using `pandas.to_sql`!\n",
    "\n",
    "NOTE: We will be using the same connection engine created earlier in this code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b452c84",
   "metadata": {},
   "source": [
    "## Create database w/ DataFrame metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2988d843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge, airport_fee]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List columns as a pandas.DataFrame\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd365c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table in the DB from with pandas .to_sql method\n",
    "df.head(n=0).to_sql(name = 'yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80708338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time df.to_sql(name = 'yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f3896b",
   "metadata": {},
   "source": [
    "## Ingest Data into the database\n",
    "\n",
    "### `pandas.DataFrame` iterator\n",
    "\n",
    "With the `pandas.DataFrame` iterator we can upload data in batches/chunksto our database.\n",
    "\n",
    "That's usually the way to go for tables with many, many records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "933fe57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame iterator\n",
    "df_iter = pd.read_csv('../yellow_tripdata_2021-01.csv', iterator = True, chunksize=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1fefe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-07 16:21:27.865335 - [ Chunk 01/14 ] - Chunk ingested into database in 14.021 seconds\n",
      "2022-08-07 16:21:41.943959 - [ Chunk 02/14 ] - Chunk ingested into database in 13.942 seconds\n",
      "2022-08-07 16:21:56.107810 - [ Chunk 03/14 ] - Chunk ingested into database in 14.03 seconds\n",
      "2022-08-07 16:22:10.792055 - [ Chunk 04/14 ] - Chunk ingested into database in 14.554 seconds\n",
      "2022-08-07 16:22:25.367912 - [ Chunk 05/14 ] - Chunk ingested into database in 14.453 seconds\n",
      "2022-08-07 16:22:40.166606 - [ Chunk 06/14 ] - Chunk ingested into database in 14.674 seconds\n",
      "2022-08-07 16:22:57.108284 - [ Chunk 07/14 ] - Chunk ingested into database in 16.812 seconds\n",
      "2022-08-07 16:23:13.044763 - [ Chunk 08/14 ] - Chunk ingested into database in 15.812 seconds\n",
      "2022-08-07 16:23:28.679159 - [ Chunk 09/14 ] - Chunk ingested into database in 15.511 seconds\n",
      "2022-08-07 16:23:45.372157 - [ Chunk 10/14 ] - Chunk ingested into database in 16.566 seconds\n",
      "2022-08-07 16:24:07.106220 - [ Chunk 11/14 ] - Chunk ingested into database in 21.606 seconds\n",
      "2022-08-07 16:24:21.554231 - [ Chunk 12/14 ] - Chunk ingested into database in 14.326 seconds\n",
      "2022-08-07 16:24:36.557639 - [ Chunk 13/14 ] - Chunk ingested into database in 14.881 seconds\n",
      "2022-08-07 16:24:46.614881 - [ Chunk 14/14 ] - Chunk ingested into database in 9.979 seconds\n"
     ]
    }
   ],
   "source": [
    "chunksize = 100_000\n",
    "n_chunks_total = np.ceil(df.shape[0] / chunksize).astype('int8')\n",
    "\n",
    "# Uncomment to reset db\n",
    "# df.head(n=0).to_sql(name = 'yellow_taxi_data', con=engine, if_exists='replace')\n",
    "\n",
    "for i, df_chunk in enumerate(df_iter):\n",
    "    \n",
    "    t_start = time()\n",
    "    \n",
    "    # Change date columns to datetime type objects\n",
    "    df_chunk['tpep_pickup_datetime'] = pd.to_datetime(df_chunk['tpep_pickup_datetime'])\n",
    "    df_chunk['tpep_dropoff_datetime'] = pd.to_datetime(df_chunk['tpep_dropoff_datetime'])\n",
    "    \n",
    "    # Append chunk to the database\n",
    "    df_chunk.to_sql(name = 'yellow_taxi_data', con=engine, if_exists='append')\n",
    "    \n",
    "    t_end = time()\n",
    "    \n",
    "    print(f'{datetime.datetime.now()} - [ Chunk {(i + 1):02d}/{n_chunks_total} ] - Chunk ingested into database in {round((t_end - t_start), 3)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3f552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
